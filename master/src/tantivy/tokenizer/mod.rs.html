<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="generator" content="rustdoc">
    <meta name="description" content="Source to the Rust file `src/tokenizer/mod.rs`.">
    <meta name="keywords" content="rust, rustlang, rust-lang">

    <title>mod.rs.html -- source</title>

    <link rel="stylesheet" type="text/css" href="../../../normalize.css">
    <link rel="stylesheet" type="text/css" href="../../../rustdoc.css" id="mainThemeStyle">
    
    <link rel="stylesheet" type="text/css" href="../../../dark.css">
    <link rel="stylesheet" type="text/css" href="../../../main.css" id="themeStyle">
    <script src="../../../storage.js"></script>
    

    
    
</head>
<body class="rustdoc source">
    <!--[if lte IE 8]>
    <div class="warning">
        This old browser is unsupported and will most likely display funky
        things.
    </div>
    <![endif]-->

    

    <nav class="sidebar">
        <div class="sidebar-menu">&#9776;</div>
        <a href='../../../tantivy/index.html'><img src='http://fulmicoton.com/tantivy-logo/tantivy-logo.png' alt='logo' width='100'></a>
        
    </nav>

    <div class="theme-picker">
        <button id="theme-picker" aria-label="Pick another theme!">
            <img src="../../../brush.svg" width="18" alt="Pick another theme!">
        </button>
        <div id="theme-choices"></div>
    </div>
    <script src="../../../theme.js"></script>
    <nav class="sub">
        <form class="search-form js-only">
            <div class="search-container">
                <input class="search-input" name="search"
                       autocomplete="off"
                       placeholder="Click or press ‘S’ to search, ‘?’ for more options…"
                       type="search">
            </div>
        </form>
    </nav>

    <section id='main' class="content"><pre class="line-numbers"><span id="1">  1</span>
<span id="2">  2</span>
<span id="3">  3</span>
<span id="4">  4</span>
<span id="5">  5</span>
<span id="6">  6</span>
<span id="7">  7</span>
<span id="8">  8</span>
<span id="9">  9</span>
<span id="10"> 10</span>
<span id="11"> 11</span>
<span id="12"> 12</span>
<span id="13"> 13</span>
<span id="14"> 14</span>
<span id="15"> 15</span>
<span id="16"> 16</span>
<span id="17"> 17</span>
<span id="18"> 18</span>
<span id="19"> 19</span>
<span id="20"> 20</span>
<span id="21"> 21</span>
<span id="22"> 22</span>
<span id="23"> 23</span>
<span id="24"> 24</span>
<span id="25"> 25</span>
<span id="26"> 26</span>
<span id="27"> 27</span>
<span id="28"> 28</span>
<span id="29"> 29</span>
<span id="30"> 30</span>
<span id="31"> 31</span>
<span id="32"> 32</span>
<span id="33"> 33</span>
<span id="34"> 34</span>
<span id="35"> 35</span>
<span id="36"> 36</span>
<span id="37"> 37</span>
<span id="38"> 38</span>
<span id="39"> 39</span>
<span id="40"> 40</span>
<span id="41"> 41</span>
<span id="42"> 42</span>
<span id="43"> 43</span>
<span id="44"> 44</span>
<span id="45"> 45</span>
<span id="46"> 46</span>
<span id="47"> 47</span>
<span id="48"> 48</span>
<span id="49"> 49</span>
<span id="50"> 50</span>
<span id="51"> 51</span>
<span id="52"> 52</span>
<span id="53"> 53</span>
<span id="54"> 54</span>
<span id="55"> 55</span>
<span id="56"> 56</span>
<span id="57"> 57</span>
<span id="58"> 58</span>
<span id="59"> 59</span>
<span id="60"> 60</span>
<span id="61"> 61</span>
<span id="62"> 62</span>
<span id="63"> 63</span>
<span id="64"> 64</span>
<span id="65"> 65</span>
<span id="66"> 66</span>
<span id="67"> 67</span>
<span id="68"> 68</span>
<span id="69"> 69</span>
<span id="70"> 70</span>
<span id="71"> 71</span>
<span id="72"> 72</span>
<span id="73"> 73</span>
<span id="74"> 74</span>
<span id="75"> 75</span>
<span id="76"> 76</span>
<span id="77"> 77</span>
<span id="78"> 78</span>
<span id="79"> 79</span>
<span id="80"> 80</span>
<span id="81"> 81</span>
<span id="82"> 82</span>
<span id="83"> 83</span>
<span id="84"> 84</span>
<span id="85"> 85</span>
<span id="86"> 86</span>
<span id="87"> 87</span>
<span id="88"> 88</span>
<span id="89"> 89</span>
<span id="90"> 90</span>
<span id="91"> 91</span>
<span id="92"> 92</span>
<span id="93"> 93</span>
<span id="94"> 94</span>
<span id="95"> 95</span>
<span id="96"> 96</span>
<span id="97"> 97</span>
<span id="98"> 98</span>
<span id="99"> 99</span>
<span id="100">100</span>
<span id="101">101</span>
<span id="102">102</span>
<span id="103">103</span>
<span id="104">104</span>
<span id="105">105</span>
<span id="106">106</span>
<span id="107">107</span>
<span id="108">108</span>
<span id="109">109</span>
<span id="110">110</span>
<span id="111">111</span>
<span id="112">112</span>
<span id="113">113</span>
<span id="114">114</span>
<span id="115">115</span>
<span id="116">116</span>
<span id="117">117</span>
<span id="118">118</span>
<span id="119">119</span>
<span id="120">120</span>
<span id="121">121</span>
<span id="122">122</span>
<span id="123">123</span>
<span id="124">124</span>
<span id="125">125</span>
<span id="126">126</span>
<span id="127">127</span>
<span id="128">128</span>
<span id="129">129</span>
<span id="130">130</span>
<span id="131">131</span>
<span id="132">132</span>
<span id="133">133</span>
<span id="134">134</span>
<span id="135">135</span>
<span id="136">136</span>
<span id="137">137</span>
<span id="138">138</span>
<span id="139">139</span>
<span id="140">140</span>
<span id="141">141</span>
<span id="142">142</span>
<span id="143">143</span>
<span id="144">144</span>
<span id="145">145</span>
<span id="146">146</span>
<span id="147">147</span>
<span id="148">148</span>
<span id="149">149</span>
<span id="150">150</span>
<span id="151">151</span>
<span id="152">152</span>
<span id="153">153</span>
<span id="154">154</span>
<span id="155">155</span>
<span id="156">156</span>
<span id="157">157</span>
<span id="158">158</span>
<span id="159">159</span>
<span id="160">160</span>
<span id="161">161</span>
<span id="162">162</span>
<span id="163">163</span>
<span id="164">164</span>
<span id="165">165</span>
<span id="166">166</span>
<span id="167">167</span>
<span id="168">168</span>
<span id="169">169</span>
<span id="170">170</span>
<span id="171">171</span>
<span id="172">172</span>
<span id="173">173</span>
<span id="174">174</span>
<span id="175">175</span>
<span id="176">176</span>
<span id="177">177</span>
<span id="178">178</span>
<span id="179">179</span>
<span id="180">180</span>
<span id="181">181</span>
<span id="182">182</span>
<span id="183">183</span>
<span id="184">184</span>
<span id="185">185</span>
<span id="186">186</span>
<span id="187">187</span>
<span id="188">188</span>
<span id="189">189</span>
<span id="190">190</span>
<span id="191">191</span>
<span id="192">192</span>
<span id="193">193</span>
<span id="194">194</span>
<span id="195">195</span>
<span id="196">196</span>
<span id="197">197</span>
<span id="198">198</span>
<span id="199">199</span>
<span id="200">200</span>
<span id="201">201</span>
<span id="202">202</span>
<span id="203">203</span>
<span id="204">204</span>
<span id="205">205</span>
<span id="206">206</span>
<span id="207">207</span>
<span id="208">208</span>
<span id="209">209</span>
<span id="210">210</span>
<span id="211">211</span>
<span id="212">212</span>
<span id="213">213</span>
<span id="214">214</span>
<span id="215">215</span>
<span id="216">216</span>
<span id="217">217</span>
<span id="218">218</span>
<span id="219">219</span>
<span id="220">220</span>
<span id="221">221</span>
<span id="222">222</span>
<span id="223">223</span>
<span id="224">224</span>
<span id="225">225</span>
<span id="226">226</span>
<span id="227">227</span>
<span id="228">228</span>
<span id="229">229</span>
<span id="230">230</span>
<span id="231">231</span>
<span id="232">232</span>
<span id="233">233</span>
<span id="234">234</span>
<span id="235">235</span>
<span id="236">236</span>
<span id="237">237</span>
<span id="238">238</span>
<span id="239">239</span>
<span id="240">240</span>
<span id="241">241</span>
<span id="242">242</span>
<span id="243">243</span>
<span id="244">244</span>
<span id="245">245</span>
<span id="246">246</span>
<span id="247">247</span>
</pre><pre class="rust ">
<span class="doccomment">//! Tokenizer are in charge of chopping text into a stream of tokens</span>
<span class="doccomment">//! ready for indexing.</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! You must define in your schema which tokenizer should be used for</span>
<span class="doccomment">//! each of your fields :</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! ```</span>
<span class="doccomment">//! extern crate tantivy;</span>
<span class="doccomment">//! use tantivy::schema::*;</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! # fn main() {</span>
<span class="doccomment">//! let mut schema_builder = SchemaBuilder::new();</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! let text_options = TextOptions::default()</span>
<span class="doccomment">//!     .set_indexing_options(</span>
<span class="doccomment">//!         TextFieldIndexing::default()</span>
<span class="doccomment">//!             .set_tokenizer(&quot;en_stem&quot;)</span>
<span class="doccomment">//!             .set_index_option(IndexRecordOption::Basic)</span>
<span class="doccomment">//!     )</span>
<span class="doccomment">//!     .set_stored();</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! let id_options = TextOptions::default()</span>
<span class="doccomment">//!     .set_indexing_options(</span>
<span class="doccomment">//!         TextFieldIndexing::default()</span>
<span class="doccomment">//!             .set_tokenizer(&quot;raw_ids&quot;)</span>
<span class="doccomment">//!             .set_index_option(IndexRecordOption::WithFreqsAndPositions)</span>
<span class="doccomment">//!     )</span>
<span class="doccomment">//!     .set_stored();</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! schema_builder.add_text_field(&quot;title&quot;, text_options.clone());</span>
<span class="doccomment">//! schema_builder.add_text_field(&quot;text&quot;, text_options);</span>
<span class="doccomment">//! schema_builder.add_text_field(&quot;uuid&quot;, id_options);</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! let schema = schema_builder.build();</span>
<span class="doccomment">//! # }</span>
<span class="doccomment">//! ```</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! By default, `tantivy` offers the following tokenizers:</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! ## `default`</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! `default` is the tokenizer that will be used if you do not</span>
<span class="doccomment">//! assign a specific tokenizer to your text field.</span>
<span class="doccomment">//! It will chop your text on punctuation and whitespaces,</span>
<span class="doccomment">//! removes tokens that are longer than 40 chars, and lowercase your text.</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! ## `raw`</span>
<span class="doccomment">//! Does not actual tokenizer your text. It keeps it entirely unprocessed.</span>
<span class="doccomment">//! It can be useful to index uuids, or urls for instance.</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! ## `en_stem`</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! In addition to what `default` does, the `en_stem` tokenizer also</span>
<span class="doccomment">//! apply stemming to your tokens. Stemming consists in trimming words to</span>
<span class="doccomment">//! remove their inflection. This tokenizer is slower than the default one,</span>
<span class="doccomment">//! but is recommended to improve recall.</span>
<span class="doccomment">//!</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! # Custom tokenizers</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! You can write your own tokenizer by implementing the [`Tokenizer`](./trait.Tokenizer.html)</span>
<span class="doccomment">//! or you can extend an existing [`Tokenizer`](./trait.Tokenizer.html) by chaining it several</span>
<span class="doccomment">//! [`TokenFilter`s](./trait.TokenFilter.html).</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! For instance, the `en_stem` is defined as follows.</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! ```rust</span>
<span class="doccomment">//! # extern crate tantivy;</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! use tantivy::tokenizer::*;</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! # fn main() {</span>
<span class="doccomment">//! let en_stem = SimpleTokenizer</span>
<span class="doccomment">//!     .filter(RemoveLongFilter::limit(40))</span>
<span class="doccomment">//!     .filter(LowerCaser)</span>
<span class="doccomment">//!     .filter(Stemmer::new());</span>
<span class="doccomment">//! # }</span>
<span class="doccomment">//! ```</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! Once your tokenizer is defined, you need to</span>
<span class="doccomment">//! register it with a name in your index&#39;s [`TokenizerManager`](./struct.TokenizerManager.html).</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! ```</span>
<span class="doccomment">//! # extern crate tantivy;</span>
<span class="doccomment">//! # use tantivy::schema::SchemaBuilder;</span>
<span class="doccomment">//! # use tantivy::tokenizer::*;</span>
<span class="doccomment">//! # use tantivy::Index;</span>
<span class="doccomment">//! # fn main() {</span>
<span class="doccomment">//! # let custom_en_tokenizer = SimpleTokenizer;</span>
<span class="doccomment">//! # let schema = SchemaBuilder::new().build();</span>
<span class="doccomment">//! let index = Index::create_in_ram(schema);</span>
<span class="doccomment">//! index.tokenizers()</span>
<span class="doccomment">//!      .register(&quot;custom_en&quot;, custom_en_tokenizer);</span>
<span class="doccomment">//! # }</span>
<span class="doccomment">//! ```</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! If you built your schema programmatically, a complete example</span>
<span class="doccomment">//! could like this for instance.</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! # Example</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! ```</span>
<span class="doccomment">//! extern crate tantivy;</span>
<span class="doccomment">//! use tantivy::schema::{SchemaBuilder, IndexRecordOption, TextOptions, TextFieldIndexing};</span>
<span class="doccomment">//! use tantivy::tokenizer::*;</span>
<span class="doccomment">//! use tantivy::Index;</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! # fn main() {</span>
<span class="doccomment">//! let mut schema_builder = SchemaBuilder::new();</span>
<span class="doccomment">//! let text_field_indexing = TextFieldIndexing::default()</span>
<span class="doccomment">//!     .set_tokenizer(&quot;custom_en&quot;)</span>
<span class="doccomment">//!     .set_index_option(IndexRecordOption::WithFreqsAndPositions);</span>
<span class="doccomment">//! let text_options = TextOptions::default()</span>
<span class="doccomment">//!     .set_indexing_options(text_field_indexing)</span>
<span class="doccomment">//!     .set_stored();</span>
<span class="doccomment">//! schema_builder.add_text_field(&quot;title&quot;, text_options);</span>
<span class="doccomment">//! let schema = schema_builder.build();</span>
<span class="doccomment">//! let index = Index::create_in_ram(schema);</span>
<span class="doccomment">//!</span>
<span class="doccomment">//! // We need to register our tokenizer :</span>
<span class="doccomment">//! let custom_en_tokenizer = SimpleTokenizer</span>
<span class="doccomment">//!     .filter(RemoveLongFilter::limit(40))</span>
<span class="doccomment">//!     .filter(LowerCaser);</span>
<span class="doccomment">//! index</span>
<span class="doccomment">//!     .tokenizers()</span>
<span class="doccomment">//!     .register(&quot;custom_en&quot;, custom_en_tokenizer);</span>
<span class="doccomment">//! // ...</span>
<span class="doccomment">//! # }</span>
<span class="doccomment">//! ```</span>
<span class="doccomment">//!</span>
<span class="kw">mod</span> <span class="ident">tokenizer</span>;
<span class="kw">mod</span> <span class="ident">simple_tokenizer</span>;
<span class="kw">mod</span> <span class="ident">lower_caser</span>;
<span class="kw">mod</span> <span class="ident">remove_long</span>;
<span class="kw">mod</span> <span class="ident">stemmer</span>;
<span class="kw">mod</span> <span class="ident">facet_tokenizer</span>;
<span class="kw">mod</span> <span class="ident">tokenizer_manager</span>;
<span class="kw">mod</span> <span class="ident">japanese_tokenizer</span>;
<span class="kw">mod</span> <span class="ident">token_stream_chain</span>;
<span class="kw">mod</span> <span class="ident">raw_tokenizer</span>;
<span class="kw">mod</span> <span class="ident">alphanum_only</span>;

<span class="kw">pub</span> <span class="kw">use</span> <span class="self">self</span>::<span class="ident">alphanum_only</span>::<span class="ident">AlphaNumOnlyFilter</span>;
<span class="kw">pub</span> <span class="kw">use</span> <span class="self">self</span>::<span class="ident">tokenizer</span>::{<span class="ident">Token</span>, <span class="ident">TokenFilter</span>, <span class="ident">TokenStream</span>, <span class="ident">Tokenizer</span>};
<span class="kw">pub</span> <span class="kw">use</span> <span class="self">self</span>::<span class="ident">tokenizer</span>::<span class="ident">BoxedTokenizer</span>;
<span class="kw">pub</span> <span class="kw">use</span> <span class="self">self</span>::<span class="ident">tokenizer_manager</span>::<span class="ident">TokenizerManager</span>;
<span class="kw">pub</span> <span class="kw">use</span> <span class="self">self</span>::<span class="ident">simple_tokenizer</span>::<span class="ident">SimpleTokenizer</span>;
<span class="kw">pub</span> <span class="kw">use</span> <span class="self">self</span>::<span class="ident">raw_tokenizer</span>::<span class="ident">RawTokenizer</span>;
<span class="kw">pub</span>(<span class="kw">crate</span>) <span class="kw">use</span> <span class="self">self</span>::<span class="ident">token_stream_chain</span>::<span class="ident">TokenStreamChain</span>;
<span class="kw">pub</span> <span class="kw">use</span> <span class="self">self</span>::<span class="ident">japanese_tokenizer</span>::<span class="ident">JapaneseTokenizer</span>;
<span class="kw">pub</span> <span class="kw">use</span> <span class="self">self</span>::<span class="ident">remove_long</span>::<span class="ident">RemoveLongFilter</span>;
<span class="kw">pub</span> <span class="kw">use</span> <span class="self">self</span>::<span class="ident">lower_caser</span>::<span class="ident">LowerCaser</span>;
<span class="kw">pub</span> <span class="kw">use</span> <span class="self">self</span>::<span class="ident">stemmer</span>::<span class="ident">Stemmer</span>;
<span class="kw">pub</span> <span class="kw">use</span> <span class="self">self</span>::<span class="ident">facet_tokenizer</span>::<span class="ident">FacetTokenizer</span>;

<span class="attribute">#[<span class="ident">cfg</span>(<span class="ident">test</span>)]</span>
<span class="kw">mod</span> <span class="ident">test</span> {
    <span class="kw">use</span> <span class="kw">super</span>::<span class="ident">Token</span>;
    <span class="kw">use</span> <span class="kw">super</span>::<span class="ident">TokenizerManager</span>;

    <span class="attribute">#[<span class="ident">test</span>]</span>
    <span class="kw">fn</span> <span class="ident">test_raw_tokenizer</span>() {
        <span class="kw">let</span> <span class="ident">tokenizer_manager</span> <span class="op">=</span> <span class="ident">TokenizerManager</span>::<span class="ident">default</span>();
        <span class="kw">let</span> <span class="ident">en_tokenizer</span> <span class="op">=</span> <span class="ident">tokenizer_manager</span>.<span class="ident">get</span>(<span class="string">&quot;raw&quot;</span>).<span class="ident">unwrap</span>();
        <span class="kw">let</span> <span class="kw-2">mut</span> <span class="ident">tokens</span>: <span class="ident">Vec</span><span class="op">&lt;</span><span class="ident">String</span><span class="op">&gt;</span> <span class="op">=</span> <span class="macro">vec</span><span class="macro">!</span>[];
        {
            <span class="kw">let</span> <span class="kw-2">mut</span> <span class="ident">add_token</span> <span class="op">=</span> <span class="op">|</span><span class="ident">token</span>: <span class="kw-2">&amp;</span><span class="ident">Token</span><span class="op">|</span> {
                <span class="ident">tokens</span>.<span class="ident">push</span>(<span class="ident">token</span>.<span class="ident">text</span>.<span class="ident">clone</span>());
            };
            <span class="ident">en_tokenizer</span>
                .<span class="ident">token_stream</span>(<span class="string">&quot;Hello, happy tax payer!&quot;</span>)
                .<span class="ident">process</span>(<span class="kw-2">&amp;</span><span class="kw-2">mut</span> <span class="ident">add_token</span>);
        }
        <span class="macro">assert_eq</span><span class="macro">!</span>(<span class="ident">tokens</span>.<span class="ident">len</span>(), <span class="number">1</span>);
        <span class="macro">assert_eq</span><span class="macro">!</span>(<span class="kw-2">&amp;</span><span class="ident">tokens</span>[<span class="number">0</span>], <span class="string">&quot;Hello, happy tax payer!&quot;</span>);
    }

    <span class="attribute">#[<span class="ident">test</span>]</span>
    <span class="kw">fn</span> <span class="ident">test_en_tokenizer</span>() {
        <span class="kw">let</span> <span class="ident">tokenizer_manager</span> <span class="op">=</span> <span class="ident">TokenizerManager</span>::<span class="ident">default</span>();
        <span class="macro">assert</span><span class="macro">!</span>(<span class="ident">tokenizer_manager</span>.<span class="ident">get</span>(<span class="string">&quot;en_doesnotexist&quot;</span>).<span class="ident">is_none</span>());
        <span class="kw">let</span> <span class="ident">en_tokenizer</span> <span class="op">=</span> <span class="ident">tokenizer_manager</span>.<span class="ident">get</span>(<span class="string">&quot;en_stem&quot;</span>).<span class="ident">unwrap</span>();
        <span class="kw">let</span> <span class="kw-2">mut</span> <span class="ident">tokens</span>: <span class="ident">Vec</span><span class="op">&lt;</span><span class="ident">String</span><span class="op">&gt;</span> <span class="op">=</span> <span class="macro">vec</span><span class="macro">!</span>[];
        {
            <span class="kw">let</span> <span class="kw-2">mut</span> <span class="ident">add_token</span> <span class="op">=</span> <span class="op">|</span><span class="ident">token</span>: <span class="kw-2">&amp;</span><span class="ident">Token</span><span class="op">|</span> {
                <span class="ident">tokens</span>.<span class="ident">push</span>(<span class="ident">token</span>.<span class="ident">text</span>.<span class="ident">clone</span>());
            };
            <span class="ident">en_tokenizer</span>
                .<span class="ident">token_stream</span>(<span class="string">&quot;Hello, happy tax payer!&quot;</span>)
                .<span class="ident">process</span>(<span class="kw-2">&amp;</span><span class="kw-2">mut</span> <span class="ident">add_token</span>);
        }
        <span class="macro">assert_eq</span><span class="macro">!</span>(<span class="ident">tokens</span>.<span class="ident">len</span>(), <span class="number">4</span>);
        <span class="macro">assert_eq</span><span class="macro">!</span>(<span class="kw-2">&amp;</span><span class="ident">tokens</span>[<span class="number">0</span>], <span class="string">&quot;hello&quot;</span>);
        <span class="macro">assert_eq</span><span class="macro">!</span>(<span class="kw-2">&amp;</span><span class="ident">tokens</span>[<span class="number">1</span>], <span class="string">&quot;happi&quot;</span>);
        <span class="macro">assert_eq</span><span class="macro">!</span>(<span class="kw-2">&amp;</span><span class="ident">tokens</span>[<span class="number">2</span>], <span class="string">&quot;tax&quot;</span>);
        <span class="macro">assert_eq</span><span class="macro">!</span>(<span class="kw-2">&amp;</span><span class="ident">tokens</span>[<span class="number">3</span>], <span class="string">&quot;payer&quot;</span>);
    }

    <span class="attribute">#[<span class="ident">test</span>]</span>
    <span class="kw">fn</span> <span class="ident">test_jp_tokenizer</span>() {
        <span class="kw">let</span> <span class="ident">tokenizer_manager</span> <span class="op">=</span> <span class="ident">TokenizerManager</span>::<span class="ident">default</span>();
        <span class="kw">let</span> <span class="ident">en_tokenizer</span> <span class="op">=</span> <span class="ident">tokenizer_manager</span>.<span class="ident">get</span>(<span class="string">&quot;ja&quot;</span>).<span class="ident">unwrap</span>();

        <span class="kw">let</span> <span class="kw-2">mut</span> <span class="ident">tokens</span>: <span class="ident">Vec</span><span class="op">&lt;</span><span class="ident">String</span><span class="op">&gt;</span> <span class="op">=</span> <span class="macro">vec</span><span class="macro">!</span>[];
        {
            <span class="kw">let</span> <span class="kw-2">mut</span> <span class="ident">add_token</span> <span class="op">=</span> <span class="op">|</span><span class="ident">token</span>: <span class="kw-2">&amp;</span><span class="ident">Token</span><span class="op">|</span> {
                <span class="ident">tokens</span>.<span class="ident">push</span>(<span class="ident">token</span>.<span class="ident">text</span>.<span class="ident">clone</span>());
            };
            <span class="ident">en_tokenizer</span>
                .<span class="ident">token_stream</span>(<span class="string">&quot;野菜食べないとやばい!&quot;</span>)
                .<span class="ident">process</span>(<span class="kw-2">&amp;</span><span class="kw-2">mut</span> <span class="ident">add_token</span>);
        }
        <span class="macro">assert_eq</span><span class="macro">!</span>(<span class="ident">tokens</span>.<span class="ident">len</span>(), <span class="number">5</span>);
        <span class="macro">assert_eq</span><span class="macro">!</span>(<span class="kw-2">&amp;</span><span class="ident">tokens</span>[<span class="number">0</span>], <span class="string">&quot;野菜&quot;</span>);
        <span class="macro">assert_eq</span><span class="macro">!</span>(<span class="kw-2">&amp;</span><span class="ident">tokens</span>[<span class="number">1</span>], <span class="string">&quot;食べ&quot;</span>);
        <span class="macro">assert_eq</span><span class="macro">!</span>(<span class="kw-2">&amp;</span><span class="ident">tokens</span>[<span class="number">2</span>], <span class="string">&quot;ない&quot;</span>);
        <span class="macro">assert_eq</span><span class="macro">!</span>(<span class="kw-2">&amp;</span><span class="ident">tokens</span>[<span class="number">3</span>], <span class="string">&quot;と&quot;</span>);
        <span class="macro">assert_eq</span><span class="macro">!</span>(<span class="kw-2">&amp;</span><span class="ident">tokens</span>[<span class="number">4</span>], <span class="string">&quot;やばい&quot;</span>);
    }

    <span class="attribute">#[<span class="ident">test</span>]</span>
    <span class="kw">fn</span> <span class="ident">test_tokenizer_empty</span>() {
        <span class="kw">let</span> <span class="ident">tokenizer_manager</span> <span class="op">=</span> <span class="ident">TokenizerManager</span>::<span class="ident">default</span>();
        <span class="kw">let</span> <span class="ident">en_tokenizer</span> <span class="op">=</span> <span class="ident">tokenizer_manager</span>.<span class="ident">get</span>(<span class="string">&quot;en_stem&quot;</span>).<span class="ident">unwrap</span>();
        {
            <span class="kw">let</span> <span class="kw-2">mut</span> <span class="ident">tokens</span>: <span class="ident">Vec</span><span class="op">&lt;</span><span class="ident">String</span><span class="op">&gt;</span> <span class="op">=</span> <span class="macro">vec</span><span class="macro">!</span>[];
            {
                <span class="kw">let</span> <span class="kw-2">mut</span> <span class="ident">add_token</span> <span class="op">=</span> <span class="op">|</span><span class="ident">token</span>: <span class="kw-2">&amp;</span><span class="ident">Token</span><span class="op">|</span> {
                    <span class="ident">tokens</span>.<span class="ident">push</span>(<span class="ident">token</span>.<span class="ident">text</span>.<span class="ident">clone</span>());
                };
                <span class="ident">en_tokenizer</span>.<span class="ident">token_stream</span>(<span class="string">&quot; &quot;</span>).<span class="ident">process</span>(<span class="kw-2">&amp;</span><span class="kw-2">mut</span> <span class="ident">add_token</span>);
            }
            <span class="macro">assert</span><span class="macro">!</span>(<span class="ident">tokens</span>.<span class="ident">is_empty</span>());
        }
        {
            <span class="kw">let</span> <span class="kw-2">mut</span> <span class="ident">tokens</span>: <span class="ident">Vec</span><span class="op">&lt;</span><span class="ident">String</span><span class="op">&gt;</span> <span class="op">=</span> <span class="macro">vec</span><span class="macro">!</span>[];
            {
                <span class="kw">let</span> <span class="kw-2">mut</span> <span class="ident">add_token</span> <span class="op">=</span> <span class="op">|</span><span class="ident">token</span>: <span class="kw-2">&amp;</span><span class="ident">Token</span><span class="op">|</span> {
                    <span class="ident">tokens</span>.<span class="ident">push</span>(<span class="ident">token</span>.<span class="ident">text</span>.<span class="ident">clone</span>());
                };
                <span class="ident">en_tokenizer</span>.<span class="ident">token_stream</span>(<span class="string">&quot; &quot;</span>).<span class="ident">process</span>(<span class="kw-2">&amp;</span><span class="kw-2">mut</span> <span class="ident">add_token</span>);
            }
            <span class="macro">assert</span><span class="macro">!</span>(<span class="ident">tokens</span>.<span class="ident">is_empty</span>());
        }
    }

}
</pre>
</section>
    <section id='search' class="content hidden"></section>

    <section class="footer"></section>

    <aside id="help" class="hidden">
        <div>
            <h1 class="hidden">Help</h1>

            <div class="shortcuts">
                <h2>Keyboard Shortcuts</h2>

                <dl>
                    <dt><kbd>?</kbd></dt>
                    <dd>Show this help dialog</dd>
                    <dt><kbd>S</kbd></dt>
                    <dd>Focus the search field</dd>
                    <dt><kbd>↑</kbd></dt>
                    <dd>Move up in search results</dd>
                    <dt><kbd>↓</kbd></dt>
                    <dd>Move down in search results</dd>
                    <dt><kbd>↹</kbd></dt>
                    <dd>Switch tab</dd>
                    <dt><kbd>&#9166;</kbd></dt>
                    <dd>Go to active search result</dd>
                    <dt><kbd>+</kbd></dt>
                    <dd>Expand all sections</dd>
                    <dt><kbd>-</kbd></dt>
                    <dd>Collapse all sections</dd>
                </dl>
            </div>

            <div class="infos">
                <h2>Search Tricks</h2>

                <p>
                    Prefix searches with a type followed by a colon (e.g.
                    <code>fn:</code>) to restrict the search to a given type.
                </p>

                <p>
                    Accepted types are: <code>fn</code>, <code>mod</code>,
                    <code>struct</code>, <code>enum</code>,
                    <code>trait</code>, <code>type</code>, <code>macro</code>,
                    and <code>const</code>.
                </p>

                <p>
                    Search functions by type signature (e.g.
                    <code>vec -> usize</code> or <code>* -> vec</code>)
                </p>
            </div>
        </div>
    </aside>

    

    <script>
        window.rootPath = "../../../";
        window.currentCrate = "tantivy";
    </script>
    <script src="../../../main.js"></script>
    <script defer src="../../../search-index.js"></script>
</body>
</html>